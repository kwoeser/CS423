{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kwoeser/CS423/blob/main/s25_chapter1_handout.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preface\n",
        "\n",
        "I'll use this space for each chapter to note things that might have changed in the notebook since the video was recorded. The major change in this notebook (and the following chapters) is the introduction of complete code documentation and type hints on functions and methods.\n",
        "\n",
        "Mea culpa: I did not use to document my code nor place type hints. It was not worth it to me, given that Colab did nothing with it. And frankly, I think it makes the code harder to read. However, things have changed over the last several months in Colab: (1) they introduced Gemini, which can now parse doc strings (and by parse, I mean understand), and (2) they have built-in a type-checker that is pretty dang sophisticated. Together, these give you two benefits: (a) the auto-code generator has gotten quite powerful, and (2) debugging info using type hints is now available when it was not in the past.\n",
        "\n",
        "That said, I still hate writing the documentation. But another change mitigates that. I now write my code without any documentation and debug it. Then, when I am happy, I ask Gemini to fill in the doc strings and type hints. And in my view, it does a better job than I would.\n",
        "\n",
        "I am leaving how much to document up to you. I will not grade you down if you decide not to document. However, I think you would be wasting an opportunity if you did not enlist Gemini (or Claude or chatGPT) to fill out your code - it is painless and you reap benefits."
      ],
      "metadata": {
        "id": "6LHidNJWnOBh"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzDiYMkiYgRS"
      },
      "source": [
        "<center>\n",
        "<h1>Chapter One</h1>\n",
        "</center>\n",
        "\n",
        "<hr>\n",
        "\n",
        "## LEARNING OBJECTIVES:\n",
        "- Review of several semi-obscure Python constructs we will be using during course.\n",
        "- Introduction of Titanic dataset, which we will use throughout the course.\n",
        "- Simple plotting methods for data analysis.\n",
        "- First look at feature engineering using correlation analysis. A chance to dust-off your Python chops :)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Y1huouejzY5"
      },
      "source": [
        "#I. Software Engineering and Machine Learning\n",
        "<img src='https://www.dropbox.com/s/9fcc1crlxp19ijt/major_section.png?raw=1' width='300'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eak7oBljJflj"
      },
      "source": [
        "##Let's set our goals\n",
        "\n",
        "Our goals will be to (1) build and explore machine learning algorithms and (2) take our results the last mile and put our hard work into a web-based production system.\n",
        "\n",
        "There are commerical tools that focus on this problem, e.g., [Streamlit](https://www.analyticsvidhya.com/blog/2021/06/streamlit-for-ml-web-applications-customers-propensity-to-purchase/) and [FastAI](https://towardsdatascience.com/detecting-deforestation-from-satellite-images-7aa6dfbd9f61), but they are limited. We will do things from the ground up to get exactly what we want. That's why we are in Computer Science :)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##We will get to most of this\n",
        "\n",
        "<img src='https://www.dropbox.com/s/7gpvkskejk5uzl5/Screen%20Shot%202021-12-26%20at%202.15.13%20PM.png?raw=1'>"
      ],
      "metadata": {
        "id": "EUKIR2Cu0z6Y"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SESbYbE7A1IK"
      },
      "source": [
        "#Let me switch to a demo\n",
        "\n",
        "You will need to go to video here. I urge you to do this given it more visually presents the goals of the course."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SX72WL6kBLlI"
      },
      "source": [
        "\n",
        "##Prerequisites\n",
        "\n",
        "We will be programming in Python for the most part. However, much of the action will be with Python libraries. So the real skill needed is to be able to read (online) library documentation, make sense of it, and put it to use.\n",
        "\n",
        "A second skill is debugging using Gemini, or other coding assistants. At moment, Claude is my favorite but Gemini is build right into your notebook which makes is handy.\n",
        "\n",
        "We will be doing javascript programming in the latter part of the course. However, I'll keep it simple. While I encourage you to take my simple frontends and gussy them up with fancy frontend libraries you know, that is optional. It could look good on your resume but not required for the course.\n",
        "\n",
        "There will be no expectation that you have had the CS machine learning course. We will start from scratch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gl7J-ZPU-4xj"
      },
      "source": [
        "#II. The software engineering of model building\n",
        "\n",
        "A [recent article](https://www.oreilly.com/radar/mlops-and-devops-why-data-makes-it-different) notes that we need the idea of \"MLOps\":\n",
        "\n",
        "<quote>\n",
        "\"The DevOps movement in software engineering adopts well-defined processes, modern tooling, and automated workflows to streamline the process of moving from development to robust production deployments. Why can't we use MLOps to address struggles related to deploying machine learning in production too?\"\n",
        "</quote>\n",
        "\n",
        "Many of the steps of building and exploring machine learning models can be managed. We will look at the tools available to do this management.\n",
        "\n",
        "The end goal is to produce well-documented and easily-replicable machine learning pipelines that can be carried into production."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiL8bbnhCT1p"
      },
      "source": [
        "## The software engineering bridge\n",
        "\n",
        "Somewhat unique to AI-based production systems, the bridge from model building and exploration to production system is under-studied. The vast majority of **publically** available work stops short of moving to production.\n",
        "\n",
        "In this class, we will consider what information we have to record during model building that allows us to build robust systems with real end-users. Some of this includes documentation of our exploration and building process. Some of it also includes meta-information that we glean during exploration.\n",
        "\n",
        "In summary, we will consider  what a user of an AI-based system needs to know. Can we just give them a prediction and call it a day? Hint: no. What further information can we provide? Can we explain our reasoning? Hint: yes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbAjbYBBb4Oq"
      },
      "source": [
        "#III. Where Are We?\n",
        "\n",
        "<left>\n",
        "<img src='https://www.centeredrecoveryprograms.com/wp-content/uploads/2017/12/you-are-here-map-pin-location-navigation-3-d-animation_s68bji6we_thumbnail-full08.png' height = 200>\n",
        "</left>\n",
        "\n",
        "I believe all of you have used jupyter notebooks in your courses. We will use it exclusivley in this course. Yes, I said exclusively. What??? How can you run a web server in a notebook? We will find out :)\n",
        "\n",
        "We will also be using Google Colab exclusively. Some of you may be less knowledgable about Colab. So let me give you the big picture.\n",
        "\n",
        "**Jupyter notebook** This is a web-based programming environment. A Jupyter notebook is not the same thing as Python.  One type of content is Python code, although you could use other programming languages in your Jupyter notebook. One of the great features of these notebooks is that you can share them with others. BTW: Jupyter was invented by 2 (non-cs) grad students in their spare time :)\n",
        "\n",
        "**Python runtime** This is often called the \"kernel\". The runtime is hooked into a Jupyter notebook.\n",
        "\n",
        "**Google colab** We will refer to this as a \"Colab Notebook.\" In some ways this is an alternative to a Docker image. It includes most of the libraries that we will need out of the box. And it is easy to install others. It gives us a CLI to the local linux OS. It gives us (temporary) local file store. And an easy way to extend that to the permanent file store of Google Drive.\n",
        "\n",
        "**Server farm** There is a good chance that your notebook and code are actually running in Google's server-farm in the Dalles, Oregon.\n",
        "Colab gives us access to CPUs and GPUs that run on that farm.\n",
        "<center><img src='https://lh3.googleusercontent.com/jazh9k5V944pGmE6ch-GMDzobLiz-z_y3yVXjC_O9NxIfkNNf4bFIg1hr1rfUiJ87dqVYZ2i4gr7bzYr6S-Q-oU6KCx1zIPj-X1_Bw=w800-l80-sg-rj-c0xffffff' height=200>\n",
        "</center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFV785is2Ruk"
      },
      "source": [
        "So where are you at this very minute? You are working in a Jupyter notebook that is connected to a Python kernel, running on Google Colab housed in the cloud (possibly in the Beaver state). Nice!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukVljSkCjmg0"
      },
      "source": [
        "##How to turn in your notebook for grading\n",
        "\n",
        "I am going to conserve energy and reuse a video I produced for a more introductory course. I know you know most of this, so skip toward end if you want. It tells you how to get a link to turn in to Canvas for grading.\n",
        "\n",
        "[How to turn in homework.](https://uoregon.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=1e9a3050-5a56-4ce5-a14f-ac2b0171d607)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4ulUttLkLBY"
      },
      "source": [
        "<hr>\n",
        "<pre>\n",
        "\n",
        "\n",
        "</pre>\n",
        "#IV. Python review\n",
        "<img src='https://www.dropbox.com/s/9fcc1crlxp19ijt/major_section.png?raw=1' width='300'>\n",
        "\n",
        "I know you know Python. I just want to review a few ideas from Python that we will use heavily."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Type hints\n",
        "\n",
        "I know they can be a pain to document, but Gemini and Colab can make good use of them and save you debugging time. I'll introduce them gradually as we go along, but here are some things you should import."
      ],
      "metadata": {
        "id": "m378KMfV9Ku4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import types\n",
        "from typing import Dict, Any, Optional, Union, List, Set, Hashable, Literal, Tuple, Self"
      ],
      "metadata": {
        "id": "ciNgWECe9f-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEDirsBnN7rw"
      },
      "source": [
        "## f strings\n",
        "\n",
        "---\n",
        "We can build strings from pieces of text and python values. Let me show you."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLHXyn8N-kwW"
      },
      "source": [
        "a_variable = 3\n",
        "f'The letter \"a\" appears {a_variable} times in this sentence.'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8od5CmLOkRh"
      },
      "source": [
        "Without the f."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uVhtbMnOoAf"
      },
      "source": [
        "'The letter \"a\" appears {a_variable} times in this sentence.'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Other cool things you can do with f-strings\n",
        "\n",
        "https://medium.com/bitgrit-data-science-publication/python-f-strings-tricks-you-should-know-7ce094a25d43"
      ],
      "metadata": {
        "id": "0HufLykvB6sX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nl9I5w4Z5alZ"
      },
      "source": [
        "## assert statements\n",
        "\n",
        "I'll use these for both checking my work and as a replacement for a full type-checking system for functions I define.\n",
        "\n",
        "As reminder of the syntax, check this out."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vs8qRdXx5ttx"
      },
      "source": [
        "a_condition = []\n",
        "assert a_condition, f'a_condition is {a_condition} instead of True'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zG_RKrEh6Xel"
      },
      "source": [
        "If the condition evaluates to True, the assert is silent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJ7HXNVb6gvI"
      },
      "source": [
        "## asserts as type checkers\n",
        "\n",
        "I tend to use assert in function bodies as a backup to Colabs type-checking system. It is good. But it uses hard to see red underscores that you sometimes can miss. So asserts are the enforcers.\n",
        "\n",
        "You have to be careful to ask your assert questions in general to specific order. You can see that in the example code below.\n",
        "\n",
        "1. Most generally, is `x` a list?\n",
        "2. Ok, is `x` non-empty?\n",
        "3. Ok, does `x` contain all inner lists?\n",
        "\n",
        "Note in the test cases below the red underscore line. This is Colab using the types hints I have provided to warn you of issues. Also note that it seems to miss `[] `as an arg. That is Colab's fault: the type hint would normally catch it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxtkGTWS6p-G"
      },
      "source": [
        "def first_in_list_of_lists(x: List[List[Any]]) -> List[Any]:\n",
        "  assert isinstance(x,list), f'expecting x to be list but is instead {type(x)}'\n",
        "  assert len(x)>0, f'expecting x to be non-empty'\n",
        "  assert all([isinstance(y, list) for y in x]), f'expecting x to be list of lists but is instead list of {type(x[0])}'\n",
        "\n",
        "  return x[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFmNEQ4c8H2a"
      },
      "source": [
        "first_in_list_of_lists(34)  #should see red underscore as type warning"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSvOBSr98SKL"
      },
      "source": [
        "first_in_list_of_lists([])  #no red underscore but there should be - type checker could still use some improvement"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBAhKrv98X10"
      },
      "source": [
        "first_in_list_of_lists([1,2,3])  #should see red underscore"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwxPk74m8dnM"
      },
      "source": [
        "first_in_list_of_lists([[1], [2]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTlC0H5E8rSO"
      },
      "source": [
        "##list comprehensions\n",
        "\n",
        "I much prefer these over for-loops. Sometimes you need a for-loop. But many times a list comprehension will suffice."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuaKxhMi82jM"
      },
      "source": [
        "[i for i in range(10)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMcLBKm88_f3"
      },
      "source": [
        "[i if i%2==0 else -1 for i in range(10)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtKHHsww9pRL"
      },
      "source": [
        "[i for i in range(10) if i%2==0]  #subtle - this one filters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyU0RsZS9NuF"
      },
      "source": [
        "[a+b for a,b in zip([1,2,3], [4,5,6])]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_1ZVHiOUoF9"
      },
      "source": [
        "<img src='https://www.dropbox.com/s/8x575mvbi1xumje/cash_line.png?raw=1' height=3 width=500><br>\n",
        "<img src='https://www.gannett-cdn.com/-mm-/56cbeec8287997813f287995de67747ba5e101d5/c=9-0-1280-718/local/-/media/2018/02/15/Phoenix/Phoenix/636542954131413889-image.jpg' height=50>\n",
        "The Python string replace method is broken! Everyone is scrambling to fix it. But you step up to help out. You write a function `temp_replace` that does the same thing (mostly).\n",
        "\n",
        "I'll simplify and constrain `old` to be a single character."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22QduFMTAle6"
      },
      "source": [
        "def temp_replace(s: str, old: str, new: str) -> str:\n",
        "  \"\"\"Replaces all occurrences of `old` with `new` in string `s`.\n",
        "\n",
        "  This function is similar to the built-in `replace` method,\n",
        "  but it only supports replacing single characters.\n",
        "\n",
        "  Args:\n",
        "    s: The string to replace characters in.\n",
        "    old: The character to replace. Must be a single character.\n",
        "    new: The character to replace `old` with.\n",
        "\n",
        "  Returns:\n",
        "    A new string with all occurrences of `old` replaced with `new`.\n",
        "\n",
        "  Raises:\n",
        "    AssertionError: If `old` is not a single character, or if `s`,\n",
        "      `old`, or `new` are not strings.\n",
        "  \"\"\"\n",
        "  #asserts below\n",
        "  assert isinstance(s,str), f'expecting s to be str but is instead {type(s)}'\n",
        "  assert isinstance(old,str), f'expecting old to be str but is instead {type(old)}'\n",
        "  assert isinstance(new,str), f'expecting new to be str but is instead {type(new)}'\n",
        "  assert len(old)==1, f'expecting old to be single char but is len {len(old)}'\n",
        "\n",
        "  #body below - use list comprehension\n",
        "  result: List[str] =\n",
        "\n",
        "  return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74XLHxJABCd2"
      },
      "source": [
        "#test your function\n",
        "test_string = 'abcde'\n",
        "(temp_replace(test_string, 'd', 'z'), temp_replace(test_string, 'A', '4'))  #('abcze', 'abcde')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###One thing to notice\n",
        "\n",
        "I asked Gemini to fill out the function above with doc string and type hints. And note that it wrote the docstring by itself. How did it give such a precise description? Gemini can read text cells! So it read the specification I gave you in the quiz and used that to write the description. This is pretty dang powerful."
      ],
      "metadata": {
        "id": "Htq10sSNOwg-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMOBLanJ-P8N"
      },
      "source": [
        "<hr>\n",
        "<pre>\n",
        "\n",
        "\n",
        "</pre>\n",
        "#V. The pandas library\n",
        "<img src='https://www.dropbox.com/s/9fcc1crlxp19ijt/major_section.png?raw=1' width='300'>\n",
        "\n",
        "pandas has lots of tools for exploring a tabular dataset. We will touch on a few of those tools before moving on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5hWakgj-4zn"
      },
      "source": [
        "import pandas as pd  #convention to use pd as nickname - follow it!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3xvrT36A0Bn"
      },
      "source": [
        "##url is way to go\n",
        "\n",
        "It may not always be possible, but if you can get a url for your data, pandas can use it for loading. Saves messing with file paths and reading in as file. Pretty slick.\n",
        "\n",
        "And good news. If you store your data on Dropbox or GitHub or Google Sheets, you can get a url that pandas can use. If your data is at some other location on the cloud or even on your computer, the easiest is to upload it to local Colab storage (see folder icon on left) and then read from there.\n",
        "\n",
        "Below, I am accessing data I have on my Google Drive (as a Google Sheet)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKafFDa8-4zw"
      },
      "source": [
        "url = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vQjIoC4LWfiuFmnix6TUAGSOPK29QMsn5Sb9DS73mNmMqikngNSG9ntmxHUO7ySZXTPpmoP8yAV0auz/pub?output=csv'  #plain old string I got from Google Sheets\n",
        "titanic_table = pd.read_csv(url)  #using pandas to read in an entire dataset - the coolest"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhkNMAbhOrQs"
      },
      "source": [
        "len(titanic_table)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3r1rxC7VxCc"
      },
      "source": [
        "titanic_table.head()  #print first 5 rows of the table"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MUOA71eQ448"
      },
      "source": [
        "titanic_table.describe(include='all').T  #Transpose table to make more readable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iS6L0WnOEgeb"
      },
      "source": [
        "##Titanic is our jam\n",
        "\n",
        "I admit the dataset is a bit academic in the sense of who cares what happened over 100 years ago. But it has a mixture of data that will force us to use a range of data engineering tools. And these tools will come in handy on new, important and timely datasets.\n",
        "\n",
        "So it is a good place to practice getting our tools in order."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wK-5EKsfF49w"
      },
      "source": [
        "###Drop some columns\n",
        "\n",
        "Before we move on, let's focus on a subset of columns. I'll go into more detail on this in the next chapter. For now, I'll just drop some columns to simplify."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47uCJMHqGQdA"
      },
      "source": [
        "print(titanic_table.columns)  #full set of columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvRnvfroGJMy"
      },
      "source": [
        "titanic_table = titanic_table.drop(columns=['Bio', 'Occupation', 'Class/Dept', 'Cabin', 'Boat', 'Nationality', 'URL'])\n",
        "titanic_table.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvBXvv5P3RDM"
      },
      "source": [
        "<hr>\n",
        "<pre>\n",
        "\n",
        "\n",
        "</pre>\n",
        "#VI. pandas has rudimentary plotting methods\n",
        "<img src='https://www.dropbox.com/s/9fcc1crlxp19ijt/major_section.png?raw=1' width='300'>\n",
        "\n",
        "First, let me say we won't be doing any plotting beyond this chapter. This is not because I think it is unimportant, just that there are only 10 weeks in the quarter. But I hated to skip it so we will do a brief look. Plotting is the kind of thing you would typically do the first time you are handed a dataset. The goal is to get a picture of how the data is distributed and possibly correlated.\n",
        "\n",
        "I can tell you that the standard visualization/plotting library in Python is `matplotlib`. I can also tell you that it is knarly both conceptually and syntactically. I am going to rely on pandas as a \"wrapper\" for `matplotlib`. What pandas has done is give you plotting methods that hide the messy underlying `matplotlib` code. Thanks, pandas!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDTfB7QX4kOl"
      },
      "source": [
        "##The crosstab method plus the plot method\n",
        "\n",
        "I can give you, in a single line, the pandas code that can power our investigation of the Titanic data. Here it is:\n",
        "<pre>\n",
        "pd.crosstab(table[col1], table[col2]).plot(kind='bar', figsize=(10,6), grid=True, logy=True)\n",
        "</pre>\n",
        "Or with a real example that plots `Gender` against `Survived`:\n",
        "<pre>\n",
        "pd.crosstab(titanic_table['Gender'], titanic_table['Survived']).plot(kind='bar', figsize=(10,6), grid=True, logy=True)\n",
        "</pre>\n",
        "The pandas plotting method is called `plot` and comes last in the method chain. We have 1 method that preceeds it: `crosstab`, which sets up a new table (which gets thrown away after plotting) that has rows and columns set up for plotting, i.e., it is wrangled for plotting. Let's run the code and see what happens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFPZBaBVneFq"
      },
      "source": [
        "pd.crosstab(titanic_table['Gender'], titanic_table['Survived']).plot(kind='bar', figsize=(10,6), grid=True, logy=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MclglulO65rq"
      },
      "source": [
        "Let's look at the parameters to `plot`.\n",
        "<pre>\n",
        "plot(kind='bar', figsize=(10,6), grid=True, logy=True)\n",
        "</pre>\n",
        " It's a kind of  bar chart. It shows the possible values in the `Survived` column, blue being perished, orange survived. The blue line dominates if it is larger and vice versa. `figsize` says the plot should show on a 10 inch wide and 6 inch deep figure. `grid` is used to overlay the plot with grid-lines. `logy` says to scale the data on the y axis, log base 10. I chose to scale because of the tendency for small values to be lost in the plot, e.g., values of 1. With scaling they can be seen more clearly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yPKLSTQ85kH"
      },
      "source": [
        "Here is another example looking at `Class` cross `Gender`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wmvzOrg7j_r"
      },
      "source": [
        "pd.crosstab(titanic_table['Class'], titanic_table['Gender']).plot(kind='bar', figsize=(10,6), grid=True, logy=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8533YENDbbWw"
      },
      "source": [
        "## Subsetting the table\n",
        "\n",
        "There is another pandas concept that is useful. It is the idea of taking a subset of rows based on some condition(s). We can use the `query` method for this. I like query because it generally follows a style called SQL, which has been the standard used to query databases forever - talking 1970s. Here are some examples.\n",
        "<pre>\n",
        "fem3_table = titanic_table.query('Gender == \"Female\" and Class == \"C3\"')\n",
        "\n",
        "senior_table = titanic_table.query('Age > 65')\n",
        "</pre>\n",
        "The `query` method takes a single argument, a string. So that is straightforward. The complication is in how that string needs to be formatted. You have to remember these key facts:\n",
        "\n",
        "1. You do **not** have to quote column names.\n",
        "\n",
        "2. You do have to quote column **values** if they are not numeric, i.e., they are categorical.\n",
        "\n",
        "3. Do **not** quote a numeric value - just use the number.\n",
        "\n",
        "4. To do quoting, if you use a single quote for entire string, then use double-quotes for internal things.\n",
        "\n",
        "Let's try it out."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVpua4Sts2CR"
      },
      "source": [
        "c3_female_table = titanic_table.query('Gender == \"Female\" and Class == \"C3\"') #quotes around 2 column values\n",
        "c3_female_table.head(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RumLIgKApRV"
      },
      "source": [
        "Then we plot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQTHdQYEAtBt"
      },
      "source": [
        "pd.crosstab(c3_female_table['Married'], c3_female_table['Survived']).plot(kind='bar', figsize=(10,6), grid=True, logy=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CnGlQT6-tcN"
      },
      "source": [
        "###`loc` equivalent\n",
        "\n",
        "Here is equivalent using `loc`.\n",
        "Note need `&` for `and` and need parens around logical conditions. And square brackets.\n",
        "\n",
        " While the `loc` method is powerful, in this case I like `query` better :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHniD7nA-2tm"
      },
      "source": [
        "loc_c3_female_table = titanic_table.loc[(titanic_table['Gender'] == \"Female\") &\n",
        "                                        (titanic_table['Class'] == \"C3\")]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUh1W9CPA6qZ"
      },
      "source": [
        "loc_c3_female_table.head(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2bebYFpBTXU"
      },
      "source": [
        "Here's another."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWPMplapv5H1"
      },
      "source": [
        "passenger_table = titanic_table.query('Class != \"Crew\"')  #not crew, i.e., passengers only\n",
        "pd.crosstab(passenger_table['Class'], passenger_table['Survived']).plot(kind='bar', figsize=(10,6), grid=True, logy=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUV3oBwgClFw"
      },
      "source": [
        "<img src='https://www.dropbox.com/s/8x575mvbi1xumje/cash_line.png?raw=1' height=3 width=500><br>\n",
        "<img src='https://www.gannett-cdn.com/-mm-/56cbeec8287997813f287995de67747ba5e101d5/c=9-0-1280-718/local/-/media/2018/02/15/Phoenix/Phoenix/636542954131413889-image.jpg' height=50 align=center>  Please plot survival by Gender of those who were Married and joined in Cherbourg.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ap4nugZVC62i"
      },
      "source": [
        "#subset the table\n",
        "mcher_table ="
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zzp2ZolTC62i"
      },
      "source": [
        "#crosstab\n",
        "pd.crosstab("
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lv0iyz-j8Svu"
      },
      "source": [
        "##What we are not covering\n",
        "\n",
        "There is a lot more initial plotting you might want to do to gain insight into your data. You will cover that in a full-blown data science course.\n",
        "\n",
        "Our focus is on software engineering so we will move ahead with data wrangling then modeling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s38AKvHT2t1q"
      },
      "source": [
        "#Putting it All Together: Problems to Solve\n",
        "\n",
        "\n",
        "I'll give you some problems to work on. Please turn your notebook in on canvas. Make sure to make the shared link viewable by everyone.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ok_qpbLox1NR"
      },
      "source": [
        "#Challenge 1\n",
        "<img src='https://www.dropbox.com/s/3uyvp722kp5to2r/assignment.png?raw=1' width='300'>\n",
        "\n",
        "\n",
        "Define a function `add_lists` that takes 2 arguments, each a list of ints, and then pair-wise adds items to produce a new list. The one constraint is that if the sum is less than `0`, then it uses `0` for the sum.\n",
        "\n",
        "Use a list comprehension!\n",
        "\n",
        "Make sure your arguments look ok by using asserts, i.e., I want you (not Python) to produce error messages.\n",
        "\n",
        "Here are some test cases:\n",
        "<pre>\n",
        "add_lists([1,2,3], [4,5,6]) => [5,7,9]\n",
        "add_lists([1,2,3], [4,-5,-3]) => [5,0,0]\n",
        "add_lists([], []) => []\n",
        "add_lists(1,2) => your error message\n",
        "add_lists([1,2,3], [4,5]) => your error message\n",
        "add_lists([1, 2],[3, 4.5]) => your error message\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dJR2a22pi67"
      },
      "source": [
        "#your function here\n",
        "\n",
        "def add_lists(a: List[int], b: List[int]) -> List[int]:\n",
        "  \"\"\"Pair-wise adds items from two lists of integers.\n",
        "\n",
        "  This function takes two lists of integers as input and performs\n",
        "  pair-wise addition of corresponding elements. If the sum of\n",
        "  two elements is less than 0, it is replaced with 0.\n",
        "\n",
        "  Args:\n",
        "    a: The first list of integers.\n",
        "    b: The second list of integers.\n",
        "\n",
        "  Returns:\n",
        "    A new list containing the pair-wise sums, with negative sums\n",
        "    replaced by 0.\n",
        "\n",
        "  Raises:\n",
        "    AssertionError: If `a` or `b` are not lists, if they are\n",
        "      not of equal length, or if they contain elements that\n",
        "      are not integers.\n",
        "  \"\"\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wSkhkDdpmqM"
      },
      "source": [
        "assert add_lists([1,2,3], [4,5,6]) == [5,7,9]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDq4nP-iJOH8"
      },
      "source": [
        "assert add_lists([1,2,3], [4,-5,-3]) == [5,0,0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYZJQxGwJeKl"
      },
      "source": [
        "assert add_lists([], []) == []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84FxKTZXpsb4"
      },
      "source": [
        "add_lists(1,2) # notice red underscore"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUo5qw9dpw5k"
      },
      "source": [
        "add_lists([1,2,3], [4,5]) # no way presently to use typing to enforce same length - maybe in future"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POaxRS_mpzmO"
      },
      "source": [
        "add_lists([1, 2],[3, 4.5]) # notice red underscore"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ABh50H4CGEu"
      },
      "source": [
        "#Challenge 2\n",
        "<img src='https://www.dropbox.com/s/3uyvp722kp5to2r/assignment.png?raw=1' width='300'>\n",
        "\n",
        "If \"women and children first\" was the ethics of the day, use plotting to find a likely cut off age for \"children\". At what age did children perish at same rate as everyone else?\n",
        "\n",
        "Given that there was no definition of children age, it was up to officers on deck to make subjective judgement. The data helps us see what they were using.\n",
        "\n",
        "**One caveat**: since females survived at much higher rate than males, let's look at males only. This should give us a better indication of where cutoff was.\n",
        "\n",
        "Show your plots and your conclusion.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANg46mGbJp9M"
      },
      "source": [
        "#subset the table with males under 25\n",
        "male_young_table ="
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-TBYpRSJp9N"
      },
      "source": [
        "#crosstab to get survival of this group\n",
        "pd.crosstab("
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "101nLyXsC6mm"
      },
      "source": [
        "#Challenge 3\n",
        "<img src='https://www.dropbox.com/s/3uyvp722kp5to2r/assignment.png?raw=1' width='300'>\n",
        "\n",
        "Figure out how to remove duplicate rows and make sure index has no gaps.\n",
        "\n",
        "I'll give you a small table to test on. It has duplicate rows so remove one of them. Find the pandas method that deals with duplicates to do this. At the same time, look for the pandas method for filling in gaps in the index. You should be able to chain them together.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THpaDBy6D4Hp"
      },
      "source": [
        "test_df = pd.DataFrame({'a': [1,2,2,4], 'b':[3,1,1,5]})\n",
        "test_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEqGOMrrCva2"
      },
      "source": [
        "###Ok, make assert True\n",
        "\n",
        "Don't change `test_df`. Create a new table `new_df`, instead, with the changes. Here is your target. Notice the index has no gaps.\n",
        "\n",
        "<img src='https://www.dropbox.com/s/y94jo92nhdr1fr6/Screen%20Shot%202021-10-22%20at%2011.06.27%20AM.png?raw=1' height=150>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smvVrVHyEVH5"
      },
      "source": [
        "new_df =\n",
        "new_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<pre>\n",
        "     a\tb\n",
        "0\t1\t3\n",
        "1\t2\t1\n",
        "2\t4\t5\n",
        "</pre>"
      ],
      "metadata": {
        "id": "R8U8VS-zVu5o"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmsnlGz4EkV0"
      },
      "source": [
        "#don't modify this cell - make it True\n",
        "assert len(new_df)+1 == len(test_df)\n",
        "assert len(new_df.loc[2])==2, f'len is {len(new_df.loc[2])}'  #make sure column not dropped\n",
        "assert new_df.loc[2,'a']==4, f'loc[2,\"a\"] not 4 but {new_df.loc[2,\"a\"]}'  #make sure index looks ok"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTbcZiLE55_w"
      },
      "source": [
        "#Challenge 4\n",
        "<img src='https://www.dropbox.com/s/3uyvp722kp5to2r/assignment.png?raw=1' width='300'>\n",
        "\n",
        "This is a chance to get some Python practice. Here is an article that introduces a means of measuring the correlation between 2 columns. Read the article. Then implement a function `my_distance_correlation(a,b)`. Test it out on the `Age` and `Fare` columns. [Distance correlation article](https://towardsdatascience.com/introducing-distance-correlation-a-superior-correlation-metric-d569dc8900c7).\n",
        "\n",
        "I'm asking you to use the final 100 values in `Age` and `Fare` because they do not contain any NaN values, which would screw up our code.\n",
        "\n",
        "You can use a library method as an oracle:\n",
        "<pre>\n",
        "!pip install dcor\n",
        "import dcor\n",
        "\n",
        "dcor.distance_correlation(np.array(a),np.array(b))  #0.31412993552690227\n",
        "</pre>\n",
        "where `a` and `b` are the list of the **final** 100 column values in `Age` and `Fare`. You will have to slice to get the last 100. The value 0.`31412993552690227` is your target."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Hc69Jqq764N"
      },
      "source": [
        "#slice to get a and b as plain python lists (not numpy arrays)\n",
        "a =\n",
        "b =\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#your oracle\n",
        "!pip install dcor\n",
        "import dcor as dc\n",
        "import numpy as np\n",
        "\n",
        "dc.distance_correlation(np.array(a),np.array(b))  #0.31412993552690227"
      ],
      "metadata": {
        "id": "XoNz8aHIrfkR",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ca91k6g8tysE"
      },
      "source": [
        "##Here is the general formula\n",
        "\n",
        "<img src='https://www.dropbox.com/s/ywqbbd6qn8jchwu/Screen%20Shot%202021-08-27%20at%2010.44.29%20AM.png?raw=1' height=150>\n",
        "\n",
        "In words, the distance correlation (dCor) between 2 vectors X and Y is (a) the distance covariance (dCov) between X and Y, divided by (b) the distance variance (dVar) of X alone times the distance variance of Y alone taken to the .5 power (square root).\n",
        "\n",
        "We will break this into steps below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-XkkIXFz6h8"
      },
      "source": [
        "##Reminder of what is in `a` and `b`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5GRDODsz-6c"
      },
      "source": [
        "print(a[:5])  #[47.0, 54.0, 43.0, 52.0, 28.0]  #Age\n",
        "print(b[:5])  #[0.0, 55.0, 55.0, 78.0, 0.0]    #Fare"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siU5BdrHY4zb"
      },
      "source": [
        "##Constraint 1: Pure Python\n",
        "\n",
        "I would like you to practice with pure Python. No outside libraries can be used, e.g., no numpy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKLSWN1CaE23"
      },
      "source": [
        "##Constraint 2: List Comprehensions when you can\n",
        "\n",
        "Please avoid a for-loop when you can use a list comprehension instead. I'll give you hints along the way."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t73efognm2lI"
      },
      "source": [
        "##Step 4.1 Build a distance matrix for both `Age` and `Fare`\n",
        "\n",
        "Read the paper first to get a general idea of what is going on. The paper breaks computation into steps and I'll do the same. Here is the first step:\n",
        "\n",
        "<img src='https://miro.medium.com/max/1400/1*rrv85K1EkS4B9tLnugY9-Q.png'>\n",
        "\n",
        "We are building a \"distance matrix\" for each list of ages and fares. To decipher, looking at the matrix `aj,k`, the first 2 rows are as follows:\n",
        "<pre>\n",
        "[abs(a[0]-a[0]), abs(a[0]-a[1]), abs(a[0]-a[2]), ...]  #row 1\n",
        "[abs(a[1]-a[0]), abs(a[1]-a[1]), abs(a[1]-a[2]), ...]  #row 2\n",
        "...\n",
        "</pre>\n",
        "Remember `a` is a list of ages (an array, not a matrix). We are converting it to a distance matrix following method above. We should end up with a 100 by 100 matrix if `a` is length 100 to start.\n",
        "\n",
        "If you have sharp eyes, you may notice that row 1 == column 1, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9D3C85R0uomI"
      },
      "source": [
        "Please write a function that will compute a distance matrix for a python list of values.\n",
        "\n",
        "Note I am showing you scipy and numpy code that does this for you. I think it is ugly and hard to understand. I suppose its benefit is that it is fast. But might be worth looking at speed comparison with your straight Python code. Some other time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nk2_JGVee1b"
      },
      "source": [
        "'''\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "A = a[:, None]  #numpy rescaling required for pdist - yuck\n",
        "B = b[:, None]\n",
        "dmatrix_a = squareform(pdist(A))\n",
        "dmatrix_b = squareform(pdist(B))\n",
        "'''\n",
        "\n",
        "def compute_distance_matrix(a: List[float]) -> List[List[float]]:\n",
        "    \"\"\"Computes the distance matrix for a list of values.\n",
        "\n",
        "    This function takes a list of numeric values (e.g., floats)\n",
        "    and calculates the distance matrix, where each element (i, j)\n",
        "    represents the absolute difference between elements a[i] and a[j].\n",
        "\n",
        "    Args:\n",
        "    a: The list of numeric values.\n",
        "\n",
        "    Returns:\n",
        "    The distance matrix as a list of lists.\n",
        "\n",
        "    Raises:\n",
        "    AssertionError: If `a` is not a list or if it contains\n",
        "    elements that are not numeric.\n",
        "    \"\"\"\n",
        "    assert isinstance(a, list), f'expecting a to be list but is instead {type(a)}'\n",
        "    assert all([isinstance(v, (int, float)) for v in a]), f'expecting a to be list of numbers but is instead list of {type(a[0]) if len(a) > 0 else \"empty list\"}'\n",
        "\n",
        "    #your code below. I used for-loop and list-comprehension tandem."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " ac = [.3, 1.2, 5.4, 3.1]\n",
        " n = len(ac)\n",
        " [[abs(ac[i] - ac[j]) for i in range(n)] for j in range(n)]"
      ],
      "metadata": {
        "id": "LLpigeUB6LC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmbOoWRnaCbu"
      },
      "source": [
        "dmatrix_a = compute_distance_matrix(a)\n",
        "dmatrix_b = compute_distance_matrix(b)\n",
        "\n",
        "print(a)  #[47.0, 54.0, 43.0, 52.0, 28.0, 61.0, 30.0, 25.0, ...\n",
        "print('========')\n",
        "print(dmatrix_a[0])  #[0.0, 7.0, 4.0, 5.0, 19.0, 14.0, 17.0, 22.0, 15.0, ...\n",
        "print(dmatrix_a[1])  #[7.0, 0.0, 11.0, 2.0, 26.0, 7.0, 24.0, 29.0, 22.0, ...\n",
        "print(dmatrix_a[2])  #[4.0, 11.0, 0.0, 9.0, 15.0, 18.0, 13.0, 18.0, 11.0,..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2_5sXd5YxyN"
      },
      "source": [
        "print(len(dmatrix_a), len(dmatrix_a[0])) #100 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwKdpRwvHK2r"
      },
      "source": [
        "dmatrix_a[0]==[v[0] for v in dmatrix_a]  #matrix is symmetrical, row i == column i"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlVpx7XgnOvq"
      },
      "source": [
        "##Step 4.2 double centered distances\n",
        "\n",
        "<img src='https://miro.medium.com/max/9600/1*wXEgdSoxnG7SGfCbR7M7zQ.png'>\n",
        "\n",
        "I'm going to break up into sub-problems (bar over variable signifies mean):\n",
        "\n",
        "* compute `aj bar` (mean for each row, giving a 1D array)\n",
        "\n",
        "* compute `ak bar` (mean for each column, giving a 1D array). Note that while I will ask you to compute this with a separate function, you should be able to convice yourself that it is equivalent to `aj bar`, e.g., the mean of row 0 is equal to the mean of column 0, and so forth.\n",
        "\n",
        "* broadcast to get `aj. bar` (repeat `aj bar` n times to get matrix with n duplicate rows)\n",
        "\n",
        "* broadcast to get `a.k bar` (repeat `ak bar` n times to get matrix with n duplicate columns)\n",
        "\n",
        "* Now ready to do normal matrix subtraction with matrices with identical dimensions, i.e., all are 100 by 100.\n",
        "\n",
        "* Finally add in the grand mean `a.. bar` (a scalar).\n",
        "\n",
        "I'll ask you to write a set of functions to help. Then we can apply the functions to both `dmatrix_a` and `dmatrix_b`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbCnPQqJhES2"
      },
      "source": [
        "#row mean, i.e., aj bar (will get to the dot shortly)\n",
        "#numpy: dmat.mean(axis=0)\n",
        "\n",
        "def row_mean(dmat: List[List[float]]) -> List[float]:\n",
        "  \"\"\"Calculates the mean of each row in a matrix.\n",
        "\n",
        "  This function takes a matrix (represented as a list of lists)\n",
        "  and computes the mean of each row.\n",
        "\n",
        "  Args:\n",
        "    dmat: The matrix (list of lists) to calculate row means for.\n",
        "\n",
        "  Returns:\n",
        "    A list containing the mean of each row in the input matrix.\n",
        "\n",
        "  Raises:\n",
        "    AssertionError: If `dmat` is not a list, if it is empty,\n",
        "      or if it does not contain lists of equal length.\n",
        "  \"\"\"\n",
        "\n",
        "  assert isinstance(dmat, list), f'expecting dmat to be list but is instead {type(dmat)}'\n",
        "  assert len(dmat) > 0, f'expecting dmat to be non-empty'\n",
        "  assert all([len(row) == len(dmat[0]) for row in dmat]), f'expecting dmat to be list of lists of equal length'\n",
        "\n",
        "  #your code below - I used a single list-comprehension\n",
        "\n",
        "\n",
        "\n",
        "row_mean_a = row_mean(dmatrix_a)\n",
        "row_mean_b = row_mean(dmatrix_b)\n",
        "row_mean_a[:5]  #[17.82, 23.74, 15.2, 21.94, 10.8]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F75K4sGbhdlc"
      },
      "source": [
        "##column mean, i.e., ak bar (will get to the dot shortly)\n",
        "#numpy: dmat.mean(axis=1)\n",
        "\n",
        "def column_mean(dmat: List[List[float]]) -> List[float]:\n",
        "  \"\"\"Calculates the mean of each column in a matrix.\n",
        "\n",
        "  This function takes a matrix (represented as a list of lists)\n",
        "  and computes the mean of each column. It assumes the matrix\n",
        "  is square (i.e., the number of rows equals the number of columns).\n",
        "\n",
        "  Args:\n",
        "    dmat: The matrix (list of lists) to calculate column means for.\n",
        "\n",
        "  Returns:\n",
        "    A list containing the mean of each column in the input matrix.\n",
        "\n",
        "  Raises:\n",
        "    AssertionError: If `dmat` is not a list, if it is empty,\n",
        "      or if it does not contain lists of equal length.\n",
        "  \"\"\"\n",
        "\n",
        "  assert isinstance(dmat, list), f'expecting dmat to be list but is instead {type(dmat)}'\n",
        "  assert len(dmat) > 0, f'expecting dmat to be non-empty'\n",
        "  assert all([len(row) == len(dmat[0]) for row in dmat]), f'expecting dmat to be list of lists of equal length'\n",
        "\n",
        "  #your code below - I used a combination of for-loop and list-comprehension\n",
        "\n",
        "\n",
        "\n",
        "col_mean_a = column_mean(dmatrix_a)\n",
        "col_mean_b= column_mean(dmatrix_b)\n",
        "col_mean_a[:5]  #[17.82, 23.74, 15.2, 21.94, 10.8]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygVLQYdxIU2Y"
      },
      "source": [
        "row_mean_a==col_mean_a  #True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzPqovIYoBAg"
      },
      "source": [
        "##Problem of dimensions\n",
        "\n",
        "\n",
        "We need to do matrix subtraction but to do so all matrices must be of the same dimensions. We have mean values as 1D arrays so not there yet. The solution is to broadcast, i.e., convert the 1D arrays into 2D matrices that are 100 by 100.\n",
        "\n",
        "First type of broadcasting is by row. Easy peasy. We just repeat a 1D array we have n times. So now have a matrix of n rows, all identical. Specifically, a 100 by 100 matrix.\n",
        "\n",
        "Second type of broadcasting is by column. Same idea. Treat a 1D array we have as a column and repeat it to get matrix with identical columns.\n",
        "\n",
        "This gets us the final `aj. bar` and `a.k bar` that we need, both 100 by 100 matrices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VBlJoRrgcHQ"
      },
      "source": [
        "nrows = len(dmatrix_a)  #100\n",
        "ncols = len(dmatrix_a[0])  #100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebqEEa3d5Ghv"
      },
      "source": [
        "#broadcast both in one fell swoop!\n",
        "#numpy: row_matrix_a, col_matrix_a = np.meshgrid(row_mean_a, col_mean_a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Python hint\n",
        "\n",
        "row = [0,1,2,3,4]\n",
        "matrix = [row]*5\n",
        "matrix"
      ],
      "metadata": {
        "id": "wRn-EmKmee7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UF8-CgXHeCW0"
      },
      "source": [
        "from typing import List, Any\n",
        "\n",
        "def broadcast_row(row: List[Any], n: int) -> List[List[Any]]:\n",
        "  \"\"\"Duplicates a row n times to create a matrix.\n",
        "\n",
        "  This function takes a row (represented as a list) and an integer n,\n",
        "  and creates a matrix by duplicating the row n times.\n",
        "\n",
        "  Args:\n",
        "    row: The row to duplicate.\n",
        "    n: The number of times to duplicate the row.\n",
        "\n",
        "  Returns:\n",
        "    A matrix (list of lists) consisting of n copies of the input row.\n",
        "  \"\"\"\n",
        "  assert isinstance(row, list), f'expecting row to be list but is instead {type(row)}'\n",
        "  assert isinstance(n, int), f'expecting n to be int but is instead {type(n)}'\n",
        "  assert n > 0, f'expecting n to be positive but is instead {n}'\n",
        "\n",
        "  #your code below, either list-comprehension or see my hint above\n",
        "\n",
        "\n",
        "\n",
        "row_matrix_a = broadcast_row(row_mean_a, nrows)\n",
        "row_matrix_b = broadcast_row(row_mean_b, nrows)\n",
        "print(row_matrix_a[0][:10])  #[17.82, 23.74, 15.2, 21.94, 10.8, 30.32, 10.64, 11.62, 10.8, 14.24]\n",
        "print(row_matrix_a[1][:10])  #[17.82, 23.74, 15.2, 21.94, 10.8, 30.32, 10.64, 11.62, 10.8, 14.24]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34LIuhI2fERw"
      },
      "source": [
        "def broadcast_column(col: List[Any], n: int) -> List[List[Any]]:\n",
        "  \"\"\"Duplicates a column n times to create a matrix.\n",
        "\n",
        "  This function takes a column (represented as a list) and an integer n,\n",
        "  and creates a matrix by duplicating the column n times.\n",
        "\n",
        "  Args:\n",
        "    col: The column to duplicate.\n",
        "    n: The number of times to duplicate the column.\n",
        "\n",
        "  Returns:\n",
        "    A matrix (list of lists) consisting of n copies of the input column.\n",
        "    Each inner list in the matrix will represent a row, with the\n",
        "    column's values repeated n times.\n",
        "\n",
        "  Raises:\n",
        "    AssertionError: If `col` is not a list, if `n` is not an integer,\n",
        "      or if `n` is less than or equal to 0.\n",
        "  \"\"\"\n",
        "  assert isinstance(col, list), f'expecting col to be list but is instead {type(col)}'\n",
        "  assert isinstance(n, int), f'expecting n to be int but is instead {type(n)}'\n",
        "  assert n > 0, f'expecting n to be positive but is instead {n}'\n",
        "\n",
        "  #duplicate column n times - I was able to use a list comprehension and avoid for loop\n",
        "\n",
        "\n",
        "\n",
        "col_matrix_a = broadcast_column(col_mean_a, ncols)\n",
        "col_matrix_b = broadcast_column(col_mean_b, ncols)\n",
        "print(col_matrix_a[0])  #[17.82, 17.82, 17.82, 17.82, 17.82, 17.82, 17.82, 17.82, ...\n",
        "print(col_matrix_a[1])  #[23.74, 23.74, 23.74, 23.74, 23.74, 23.74, 23.74, 23.74, ..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yWYdI7zplaA"
      },
      "source": [
        "##Now we are ready to subtract\n",
        "\n",
        "<img src = 'https://www.dropbox.com/s/tz58t3e6yqcaaou/Screen%20Shot%202021-09-14%20at%209.51.26%20AM.png?raw=1' height=100>\n",
        "\n",
        "Let's dig a little deeper into this. I will choose values `j=2` and `k=4`. With 0 indexing, that represents the 3rd and 5th item in the original list.\n",
        "\n",
        "* `aj,k` represents the absolute difference between the 3rd and 5th item in our original list.\n",
        "\n",
        "* `aj. bar` actually could be read as `aj,k bar` where the dot is filled with `k`. It represents the mean of the difference of all points from item `k=4`. Remember all rows identical so can ignore `j`.\n",
        "\n",
        "* So for absolute diff between items 2 and 4, we are subtracting the mean of all diffs from item 4.\n",
        "\n",
        "* We next subtract the mean of all diffs from item 2. We throw `k` away because we just repeat the columns.\n",
        "\n",
        "So big picture, we first take the absolute diff between 2 items in our original list, item `j` and item `k`. But then we first subtract the mean of all the diffs from item `k`. Next we subtract the mean of all the diffs from item `j`. In essence, we are tempering the difference between the two items by how clustered points are around the first item and how clustered around second item. If the means are small (i.e., clustering happening), then the absolute difference between the items will dominate. If the means are large, then even a large absolute difference will be washed out."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AL-epTf4g3f_"
      },
      "source": [
        "def matrix_matrix_subtraction(mat1: List[List[Union[int, float]]], mat2: List[List[Union[int, float]]]) -> List[List[Union[int, float]]]:\n",
        "    \"\"\"Performs element-wise subtraction between two matrices.\n",
        "\n",
        "    This function takes two matrices as input and subtracts the\n",
        "    corresponding elements of the second matrix from the first matrix.\n",
        "\n",
        "    Args:\n",
        "        mat1: The first matrix.\n",
        "        mat2: The second matrix.\n",
        "\n",
        "    Returns:\n",
        "        A new matrix containing the results of the element-wise\n",
        "        subtraction.\n",
        "\n",
        "    Raises:\n",
        "        AssertionError: If the input matrices have different dimensions\n",
        "            (number of rows or columns).\n",
        "    \"\"\"\n",
        "    assert len(mat1) == len(mat2), f\"Matrices must have the same number of rows (got {len(mat1)} and {len(mat2)})\"\n",
        "    assert len(mat1[0]) == len(mat2[0]), f\"Matrices must have the same number of columns (got {len(mat1[0])} and {len(mat2[0])})\"\n",
        "\n",
        "    #your code below - I combined a for loop with a list comprehension\n",
        "\n",
        "\n",
        "\n",
        "A1 = matrix_matrix_substraction(dmatrix_a, row_matrix_a)\n",
        "A2 = matrix_matrix_substraction(A1, col_matrix_a)\n",
        "B1 = matrix_matrix_substraction(dmatrix_b, row_matrix_b)\n",
        "B2 = matrix_matrix_substraction(B1, col_matrix_b)\n",
        "print(A1[0])  #[-17.82, -16.74, -11.2, -16.94, 8.2, -16.32, 6.359999999999999, 10.38, 4.199999999999999, 12.76,\n",
        "print(A1[1])  #[-10.82, -23.74, -4.199999999999999, -19.94, 15.2, -23.32, 13.36, 17.380000000000003, 11.2,\n",
        "print(A2[0])  #[-35.64, -34.56, -29.02, -34.760000000000005, -9.620000000000001, -34.14, -11.46,\n",
        "print(A2[1])  #[-34.56, -47.48, -27.939999999999998, -43.68, -8.54, -47.06, -10.379999999999999,"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2KZ0g10p42L"
      },
      "source": [
        "##Next step is to compute the grand mean\n",
        "\n",
        "This is the `+ a.. bar` step. Because I know we will need it later (I cheated and looked ahead), I am going to ask you to write a function to compute the sum of a matrix. Then can take result and divide to get grand mean."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2gBlzf2kimX"
      },
      "source": [
        "#numpy: mat.flatten().sum()\n",
        "\n",
        "def matrix_summation(mat: List[List[Union[int, float]]]) -> Union[int, float]:\n",
        "  \"\"\"Calculates the sum of all elements in a matrix.\n",
        "\n",
        "  This function takes a matrix (represented as a list of lists)\n",
        "  and computes the sum of all its elements.\n",
        "\n",
        "  Args:\n",
        "    mat: The matrix to calculate the sum of.\n",
        "\n",
        "  Returns:\n",
        "    The sum of all elements in the matrix.\n",
        "\n",
        "  Raises:\n",
        "    AssertionError: If `mat` is not a list, or if it contains\n",
        "    elements that are not lists or numbers.\n",
        "  \"\"\"\n",
        "  assert isinstance(mat, list), f'expecting mat to be list but is instead {type(mat)}'\n",
        "  assert len(mat) > 0, f'expecting mat to be non-empty'  # Added for robustness\n",
        "  assert all([isinstance(row, list) for row in mat]), f'expecting mat to be list of lists but is instead list of {type(mat[0]) if len(mat) > 0 else \"empty list\"}'\n",
        "  assert all([isinstance(v, (int, float)) for row in mat for v in row]), f'expecting mat to be list of lists of numbers but is instead list of lists of {type(mat[0][0]) if len(mat) > 0 and len(mat[0]) > 0 else \"empty list\"}'\n",
        "\n",
        "  #your code below - I did not need a for loop\n",
        "\n",
        "\n",
        "\n",
        "grand_a = matrix_summation(dmatrix_a)/len(dmatrix_a)**2  #divide by 100*100 or 100**2\n",
        "grand_b = matrix_summation(dmatrix_b)/len(dmatrix_b)**2\n",
        "print(grand_a, grand_b)  #15.3948 46.920852000000004"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeoFhxi7idJm"
      },
      "source": [
        "##Getting close\n",
        "\n",
        "We have to add the grand mean, a scalar, into a 100 by 100 matrix. We simply add the scalar to each element. Pretty easy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luvIh9ecjGC0"
      },
      "source": [
        "#numpy: mat+scalar\n",
        "\n",
        "def matrix_scalar_addition(mat: List[List[Union[int, float]]], scalar: Union[int, float]) -> List[List[Union[int, float]]]:\n",
        "  \"\"\"Adds a scalar value to each element of a matrix.\n",
        "\n",
        "  This function takes a matrix (represented as a list of lists) and a scalar value.\n",
        "  It adds the scalar to each element of the matrix and returns a new matrix\n",
        "  containing the results.\n",
        "\n",
        "  Args:\n",
        "    mat: The matrix to add the scalar to.\n",
        "    scalar: The scalar value to add.\n",
        "\n",
        "  Returns:\n",
        "    A new matrix with the scalar added to each element.\n",
        "\n",
        "  Raises:\n",
        "    AssertionError: If `mat` is not a list, if it is empty,\n",
        "      or if it does not contain lists of equal length,\n",
        "      or if it contains elements that are not numbers.\n",
        "    AssertionError: If `scalar` is not a number.\n",
        "  \"\"\"\n",
        "  assert isinstance(mat, list), f'expecting mat to be list but is instead {type(mat)}'\n",
        "  assert len(mat) > 0, f'expecting mat to be non-empty'\n",
        "  assert all([len(row) == len(mat[0]) for row in mat]), f'expecting mat to be list of lists of equal length'\n",
        "  assert all([isinstance(v, (int, float)) for row in mat for v in row]), f'expecting mat to be list of lists of numbers but is instead list of lists of {type(mat[0][0]) if len(mat) > 0 and len(mat[0]) > 0 else \"empty list\"}'\n",
        "  assert isinstance(scalar, (int, float)), f'expecting scalar to be a number but is instead {type(scalar)}'\n",
        "\n",
        "  #your code below - I used a for loop and list comprehension combo\n",
        "\n",
        "\n",
        "\n",
        "A3 = matrix_scalar_addition(A2, grand_a)\n",
        "B3 = matrix_scalar_addition(B2, grand_b)\n",
        "print(A3[0])  #[-20.2452, -19.165200000000002, -13.6252, -19.365200000000005, 5.774799999999999, -18.7452,\n",
        "print(B3[0])  #[-19.48994799999999, 19.980852000000006, 19.980852000000006, 27.340852000000005, -19.48994799999999,"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJjq7XkzjJ0b"
      },
      "source": [
        "##Step 4.3 Distance Co-variance\n",
        "\n",
        "So what we have now is our original distance matrices tempered by means. We did this for both Age and Fare. Now we can ask if these 2 matrices are similar, i.e., correlated. We will use an idea called co-variance that can be used to check correlation between two matrices.\n",
        "\n",
        "As reminder, the plain variance of a list of values is:\n",
        "\n",
        "<img src = 'https://www.dropbox.com/s/xm3mw6lb11qyv9n/Screen%20Shot%202021-09-14%20at%2011.14.09%20AM.png?raw=1' height=100>\n",
        "\n",
        "where X are the items in the list and mu is the mean of the list. Take the square root and you get the standard deviation.\n",
        "\n",
        "Co-variance between two list of values is:\n",
        "\n",
        "<img src='https://www.dropbox.com/s/m2g42kbzd8nx3lt/Screen%20Shot%202021-09-14%20at%2011.16.25%20AM.png?raw=1' height=70>\n",
        "\n",
        "We need the covariance not of 2 lists but of 2 distance matrices. That formula is below where  `Aj,k` and `Bj,k` stand in for matrices `A3` and `B3` above.\n",
        "\n",
        "<img src='https://www.dropbox.com/s/c874n3r5fw9ycng/Screen%20Shot%202021-08-27%20at%2010.00.33%20AM.png?raw=1' height=100>\n",
        "\n",
        "Not totally clear, but the double summation is summing a matrix multiplication (different than dot product) .\n",
        "\n",
        "We already have a function to give us the sum of 2 matrices. So what we need is a function that does matrix multiplication, different than dot product.\n",
        "\n",
        "<img src='https://www.dropbox.com/s/y0avojo7kejm4uw/Screen%20Shot%202021-08-26%20at%202.27.59%20PM.png?raw=1' height=150>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSOxeLM3kgmP"
      },
      "source": [
        "#numpy: mat1*mat2\n",
        "\n",
        "def matrix_multiplication(mat1: List[List[Union[int, float]]], mat2: List[List[Union[int, float]]]) -> List[List[Union[int, float]]]:\n",
        "  \"\"\"Performs element-wise multiplication between two matrices.\n",
        "\n",
        "  This function takes two matrices as input and multiplies the corresponding\n",
        "  elements of the matrices. It assumes that the matrices have the same dimensions.\n",
        "\n",
        "  Args:\n",
        "    mat1: The first matrix.\n",
        "    mat2: The second matrix.\n",
        "\n",
        "  Returns:\n",
        "    A new matrix containing the results of the element-wise multiplication.\n",
        "\n",
        "  Raises:\n",
        "    AssertionError: If the input matrices have different dimensions\n",
        "    (number of rows or columns), or if the input is not list of lists of ints or floats.\n",
        "  \"\"\"\n",
        "  # Assertions to check input validity\n",
        "  assert isinstance(mat1, list) and isinstance(mat2, list), \"Input must be lists\"\n",
        "  assert len(mat1) == len(mat2), f\"Matrices must have the same number of rows (got {len(mat1)} and {len(mat2)})\"\n",
        "  assert len(mat1[0]) == len(mat2[0]), f\"Matrices must have the same number of columns (got {len(mat1[0])} and {len(mat2[0])})\"\n",
        "  assert all([isinstance(v, (int, float)) for row in mat1 for v in row]), f'expecting mat1 to be list of lists of numbers but is instead list of lists of {type(mat1[0][0]) if len(mat1) > 0 and len(mat1[0]) > 0 else \"empty list\"}'\n",
        "  assert all([isinstance(v, (int, float)) for row in mat2 for v in row]), f'expecting mat2 to be list of lists of numbers but is instead list of lists of {type(mat2[0][0]) if len(mat2) > 0 and len(mat2[0]) > 0 else \"empty list\"}'\n",
        "\n",
        "  #your code below - I used for loop and list comprehension combo although could also use a nested list-comprehension\n",
        "\n",
        "\n",
        "#I am doing multiplication followed by addition then division in one line.\n",
        "dcov2_x_y = matrix_summation(matrix_multiplication(A3, B3))/(nrows*ncols)\n",
        "print(dcov2_x_y)  #23.020073329600006"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IX3bljlLsl2i"
      },
      "source": [
        "##Step 4.4 The denominator\n",
        "\n",
        "We now need to turn to the denominator. It asks for the variance of each matrix separately. We need something for this:\n",
        "\n",
        "<img src='https://www.dropbox.com/s/ikq5y3mazi048ob/Screen%20Shot%202021-08-27%20at%2010.39.35%20AM.png?raw=1' height=50>\n",
        "\n",
        "If we look carefuly, this is just like `dcov2_x_y` but now `dcov2_x_x` and `dcov2_y_y`. So we do not need a new function. We can reuse what we had for `dcov2_x_y` with some minor changes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXdEqSSvtJbT"
      },
      "source": [
        "dvar2_x = matrix_summation(matrix_multiplication(A3, A3))/(nrows*ncols)\n",
        "dvar2_y = matrix_summation(matrix_multiplication(B3, B3))/(nrows*ncols)\n",
        "print(dvar2_x, dvar2_y)  #74.35493904000002 731.9244968539043"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZfqzIfXuMC4"
      },
      "source": [
        "##Step 4.5 Put it together in a function\n",
        "\n",
        "Reminder: here is the function we are trying to compute.\n",
        "\n",
        "<img src='https://www.dropbox.com/s/ywqbbd6qn8jchwu/Screen%20Shot%202021-08-27%20at%2010.44.29%20AM.png?raw=1' height=100>\n",
        "\n",
        "We have squared values in `dcov2_x_y`, `dvar2_x` and `dvar2_y`. So let's get the versions we need."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8PzIfJZu1h6"
      },
      "source": [
        "dcov_x_y = dcov2_x_y**.5\n",
        "dvar_x = dvar2_x**.5\n",
        "dvar_y = dvar2_y**.5\n",
        "print(dcov_x_y, dvar_x, dvar_y)  #4.797923856169459 8.622931000535724 27.05410314266404"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0Xvv92GvUHv"
      },
      "source": [
        "##On home stretch!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmpOrxhnvwLN"
      },
      "source": [
        "dcor_x_y = dcov_x_y/(dvar_x*dvar_y)**.5\n",
        "dcor_x_y  #0.3141299355269013"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IZ3BmG420Zw"
      },
      "source": [
        "##Now it's just copying and pasting into function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8-zrR1av3Im"
      },
      "source": [
        "def distance_correlation(a: List[Union[int, float]], b: List[Union[int, float]]) -> float:\n",
        "  \"\"\"Calculates the distance correlation between two lists of numbers.\n",
        "\n",
        "  This function implements the distance correlation algorithm to measure\n",
        "  the dependence between two variables represented as lists of numbers.\n",
        "  It uses a series of matrix operations to compute the distance correlation\n",
        "  coefficient.\n",
        "\n",
        "  Args:\n",
        "    a: The first list of numbers.\n",
        "    b: The second list of numbers.\n",
        "\n",
        "  Returns:\n",
        "    The distance correlation coefficient between the two input lists.\n",
        "\n",
        "  Raises:\n",
        "    AssertionError: If the input lists have different lengths, or if the input is not list of lists of ints or floats.\n",
        "  \"\"\"\n",
        "\n",
        "  # Assertions to check input validity\n",
        "  assert isinstance(a, list) and isinstance(b, list), \"Input must be lists\"\n",
        "  assert len(a) == len(b), f\"Input lists must have the same length (got {len(a)} and {len(b)})\"\n",
        "  assert all([isinstance(v, (int, float)) for v in a]), f'expecting a to be list of numbers but is instead list of {type(a[0]) if len(a) > 0 else \"empty list\"}'\n",
        "  assert all([isinstance(v, (int, float)) for v in b]), f'expecting b to be list of numbers but is instead list of {type(b[0]) if len(b) > 0 else \"empty list\"}'\n",
        "\n",
        "  #your code here\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMUitKr4Up4B"
      },
      "source": [
        "#test your function against oracle\n",
        "(distance_correlation(a,b), dc.distance_correlation(np.array(a),np.array(b)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-l-ZxDSa_ZR"
      },
      "source": [
        "Another small test case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjBFaAsJbEQw"
      },
      "source": [
        "distance_correlation([1,2,3,4],[5,6,7,8])  #1.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpS2NsN629Jt"
      },
      "source": [
        "##Whew - good job\n",
        "\n",
        "I think it is useful to do pure Python implementations of stats and linear algebra algorithms. Forces you to better understand what is going on."
      ]
    }
  ]
}